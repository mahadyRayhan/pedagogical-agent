{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pedagogical agents using LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a pedagogical agent using LLM, we need three basic things:\n",
    "1. A vector database/Index from knowledge base\n",
    "2. A LLM model\n",
    "3. A good prompt/question asking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new virtual environment\n",
    "- Go to the project folder\n",
    "- python3 -m venv Pagent\n",
    "- ./Pagent/Scripts/activate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Database\n",
    "We directly use Gemini to process our data. Model can process upto 1 million tokens(~700k words or  50,000 lines of code with the standard 80 characters per line). This is roughly 2000 pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/agent/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os             # Provides functions to interact with the operating system\n",
    "import time           # Allows for time-related functions, including delays\n",
    "import glob           # Enables file pattern matching (e.g., finding all files with a certain extension)\n",
    "import google.generativeai as genai  # Imports Google’s generative AI library for accessing generative AI functions\n",
    "from dotenv import load_dotenv      # Handles environment variables by loading from a .env file\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold  # Allows for setting harm categories and block thresholds\n",
    "\n",
    "# Loading environment variables from the .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GenAI Access and Initializing Core Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring Google Generative AI with the API key from environment variables\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "# Initializing key variables for later use\n",
    "model = None               # Placeholder for the generative AI model instance\n",
    "safety_settings = None     # Placeholder for safety settings to manage response sensitivity\n",
    "files = None               # Placeholder for file handling, such as for file upload or processing\n",
    "chat_session = None        # Placeholder for managing a chat session with the AI model\n",
    "cached_responses = {}      # Dictionary to store previously generated responses for faster access\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get API key\n",
    "- Day 2 pptx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Resource and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_gemini(paths, mime_type=None):\n",
    "    \"\"\"\n",
    "    Uploads specified files to the Gemini platform.\n",
    "\n",
    "    Parameters:\n",
    "    - paths (list): List of file paths to upload.\n",
    "    - mime_type (str, optional): The MIME type of the files (e.g., \"application/pdf\").\n",
    "                                 If None, the MIME type defaults to the file type.\n",
    "\n",
    "    Returns:\n",
    "    - files (list): A list of uploaded file objects, each containing metadata like display name and URI.\n",
    "\n",
    "    Workflow:\n",
    "    1. Iterates over each file path in `paths`.\n",
    "    2. Uploads the file to Gemini using `genai.upload_file()`.\n",
    "    3. Prints a confirmation message with the file's display name and URI after a successful upload.\n",
    "    4. Appends each uploaded file to the `files` list, which is returned at the end.\n",
    "    \"\"\"\n",
    "    \n",
    "    files = []\n",
    "    for path in paths:\n",
    "        # Upload each file to the generative AI platform, specifying MIME type if provided\n",
    "        file = genai.upload_file(path, mime_type=mime_type)\n",
    "        \n",
    "        # Print confirmation of each uploaded file\n",
    "        print(f\"Uploaded file '{file.display_name}' as: {file.uri}\")\n",
    "        \n",
    "        # Add the uploaded file object to the files list\n",
    "        files.append(file)\n",
    "    \n",
    "    return files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_files_active(files):\n",
    "    \"\"\"\n",
    "    Waits for each uploaded file to complete processing and become active on the Gemini platform.\n",
    "\n",
    "    Parameters:\n",
    "    - files (list): List of uploaded file objects to check for active status.\n",
    "\n",
    "    Workflow:\n",
    "    1. Displays a message to indicate waiting for file processing.\n",
    "    2. For each file in `files`, checks its processing state on the Gemini platform.\n",
    "    3. Repeatedly queries the file's state every 10 seconds until it becomes \"ACTIVE\".\n",
    "    4. Raises an exception if a file fails to reach the \"ACTIVE\" state, indicating a processing error.\n",
    "    5. Once all files are active, prints a success message.\n",
    "\n",
    "    Raises:\n",
    "    - Exception: If any file fails to process and reach the \"ACTIVE\" state.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Waiting for file processing...\")\n",
    "    for name in (file.name for file in files):\n",
    "        # Retrieve the current status of the file\n",
    "        file = genai.get_file(name)\n",
    "        \n",
    "        # Check the file status in a loop until it is marked as \"ACTIVE\"\n",
    "        while file.state.name == \"PROCESSING\":\n",
    "            print(\".\", end=\"\", flush=True)  # Indicate processing with dots\n",
    "            time.sleep(10)  # Wait 10 seconds before checking again\n",
    "            file = genai.get_file(name)\n",
    "        \n",
    "        # Raise an error if file processing failed\n",
    "        if file.state.name != \"ACTIVE\":\n",
    "            raise Exception(f\"File {file.name} failed to process\")\n",
    "    \n",
    "    # Success message when all files are ready for use\n",
    "    print(\"...all files ready\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_genai():\n",
    "    \"\"\"\n",
    "    Configures the generative AI model with safety settings and generation parameters, and starts a chat session.\n",
    "\n",
    "    Workflow:\n",
    "    1. Defines safety settings to manage the filtering of specific content categories.\n",
    "    2. Sets generation configuration parameters for controlling response generation.\n",
    "    3. Instantiates the `GenerativeModel` with specified settings.\n",
    "    4. Initializes a chat session with the model for interactive conversations.\n",
    "\n",
    "    Attributes:\n",
    "    - safety_settings (dict): Configuration for blocking various content harm categories (e.g., hate speech, harassment).\n",
    "    - generation_config (dict): Settings that control generation behavior, such as `temperature` and `max_output_tokens`.\n",
    "    - model (GenerativeModel): The generative model instance configured with the specified parameters.\n",
    "    - chat_session (ChatSession): A chat session object for managing interactions with the model.\n",
    "    \"\"\"\n",
    "    global model, safety_settings, chat_session, generation_config\n",
    "    # Define safety settings for different types of harmful content\n",
    "    safety_settings = {\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    }\n",
    "    \n",
    "    # Configure generation parameters to control response characteristics\n",
    "    generation_config = {\n",
    "        \"temperature\": 0,              # Determines randomness in generation; 0 means deterministic output\n",
    "        \"top_p\": 0.95,                 # Controls cumulative probability for sampling\n",
    "        \"top_k\": 64,                   # Limits the sampling pool to the top 64 tokens\n",
    "        \"max_output_tokens\": 8192,     # Sets the maximum number of tokens for the generated response\n",
    "        \"response_mime_type\": \"text/plain\",  # Specifies response type as plain text\n",
    "    }\n",
    "    \n",
    "    # Initialize the generative AI model with specified settings\n",
    "    model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\", generation_config=generation_config)\n",
    "    \n",
    "    # Start a new chat session for ongoing interactions\n",
    "    chat_session = model.start_chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resources(load_resource=False):\n",
    "    \"\"\"\n",
    "    Loads resource files into the system, specifically uploading PDFs from the 'uSucceed_resource' directory\n",
    "    to the Gemini AI platform if necessary. \n",
    "\n",
    "    Parameters:\n",
    "    - load_resource (bool): If True, forces re-loading of resource files. Defaults to False.\n",
    "\n",
    "    Workflow:\n",
    "    1. Checks if resource files need to be loaded, based on `load_resource` or the existence of `files`.\n",
    "    2. Uses `glob` to find all PDFs in the specified 'uSucceed_resource' folder.\n",
    "    3. Calls `upload_to_gemini()` to upload the PDFs to Gemini for further processing.\n",
    "    4. Invokes `wait_for_files_active()` to ensure all files are uploaded and ready for use.\n",
    "    5. Configures the generative AI system with `configure_genai()` for effective processing.\n",
    "    \"\"\"\n",
    "    global files\n",
    "    if load_resource or not files:\n",
    "        # Retrieve all PDF files in the specified directory\n",
    "        file_paths = glob.glob(\"../uSucceed_resource/*.pdf\")\n",
    "        \n",
    "        # Upload files to the generative AI platform with specified MIME type\n",
    "        files = upload_to_gemini(file_paths, mime_type=\"application/pdf\")\n",
    "        \n",
    "        # Ensure the files are active and ready for use\n",
    "        wait_for_files_active(files)\n",
    "        \n",
    "        # Set up the generative AI with any necessary configurations\n",
    "        configure_genai()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model configuration\n",
    "For any LLM moels, we need a model configuration or model text generation configuration. This actually control models text generation capabilities. <br>\n",
    "Temperature: controls output generation. For T=0, The model produces deterministic output, meaning it will always generate the same response given the same input. This is for consistency. <br> <br>\n",
    "But for Gemini, we need one more configuration. which is security parameters. Google is very concerned about their security. So you need to configure the security parameters:\n",
    "- HATE_SPEECH\n",
    "- HARASSMENT\n",
    "- SEXUALLY_EXPLICIT\n",
    "- DANGEROUS_CONTENT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Type Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_query_type(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Detects the type of query based on keywords, helping prioritize relevant documents.\n",
    "\n",
    "    Parameters:\n",
    "    - query (str): The user's input question or query.\n",
    "\n",
    "    Returns:\n",
    "    - str: A category label for the query type, either 'location', 'cybersecurity', 'system', or 'other'.\n",
    "\n",
    "    Workflow:\n",
    "    1. Defines sets of keywords for three categories: location-based, cybersecurity-related, and system-related queries.\n",
    "    2. Converts the query to lowercase for case-insensitive matching.\n",
    "    3. Checks if any keywords from each category are present in the query.\n",
    "    4. Returns the corresponding category if keywords are found, or 'other' if no keywords match.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define keyword lists for each query category\n",
    "    location_keywords = ['room', 'location', 'where', 'place', 'area', 'task']\n",
    "    security_keywords = [\n",
    "        'security', 'cyber', 'attack', 'threat', 'protection', 'ddos', 'dns', \n",
    "        'firewall', 'encryption', 'malware', 'phishing', 'ransomware', \n",
    "        'vulnerability', 'penetration', 'breach', 'authentication', 'intrusion',\n",
    "        'zero-day', 'exploit', 'mitigation', 'defense', 'incident', 'forensics',\n",
    "        'safety', 'network security', 'data breach', 'password', 'access control'\n",
    "    ]\n",
    "\n",
    "    system_keywords = [\n",
    "        'controller', 'system', 'asset', 'configuration', 'architecture', \n",
    "        'setup', 'installation', 'framework', 'protocol', 'integration', \n",
    "        'hardware', 'software', 'deployment', 'infrastructure', 'operating system', \n",
    "        'network', 'server', 'database', 'automation', 'monitoring', \n",
    "        'maintenance', 'device', 'tool', 'resource management', 'scalability'\n",
    "    ]\n",
    "\n",
    "    \n",
    "    # Convert query to lowercase for case-insensitive comparison\n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    # Match keywords to categorize the query type\n",
    "    if any(keyword in query_lower for keyword in location_keywords):\n",
    "        return 'location'\n",
    "    elif any(keyword in query_lower for keyword in security_keywords):\n",
    "        return 'cybersecurity'\n",
    "    elif any(keyword in query_lower for keyword in system_keywords):\n",
    "        return 'system'\n",
    "    \n",
    "    # Default return for queries that don't match any category\n",
    "    return 'other'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Processing and Answer Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(query_type: str, query: str) -> str:\n",
    "    \"\"\"Generate context-aware prompt based on query type\"\"\"\n",
    "    prompts = {\n",
    "        'location': \"\"\"You are a location-aware assistant. For questions about rooms or tasks:\n",
    "                     1. ONLY use information from 'Rooms_And_Tasks.pdf'\n",
    "                     2. Ignore all other documents completely for room/task questions\n",
    "                     3. Provide specific task details for the requested room\n",
    "                     4. If the information isn't in Rooms_And_Tasks.pdf, say \"I cannot find information about this room/task in the available documents.\"\n",
    "                     \n",
    "                     Question: {query}\"\"\",\n",
    "                     \n",
    "        'cybersecurity': \"\"\"You are a cybersecurity expert. For security questions:\n",
    "                           1. Prioritize information from cybersecurity guides and best practices\n",
    "                           2. Provide specific, actionable security information\n",
    "                           3. Only include room or system information if directly relevant to security\n",
    "                           \n",
    "                           Question: {query}\"\"\",\n",
    "        \n",
    "        'system': \"\"\"You are a system configuration assistant. For system questions:\n",
    "                    1. Focus on technical configuration and asset details\n",
    "                    2. Reference room information only if relevant to system setup\n",
    "                    3. Include security considerations only if directly applicable\n",
    "                    \n",
    "                    Question: {query}\"\"\",\n",
    "        \n",
    "        # 'other': \"\"\"You are a helpful assistant. Please answer the following question:\n",
    "        #            {query}\"\"\"\n",
    "        'other': \"\"\"You are a helpful assistant. Answer the following question ONLY if the information is found in the provided documents. If the requested information is not available in the resources, respond with: \n",
    "                     \"I cannot answer this question based on the available documents.\"\n",
    "                    Question: {query}\"\"\"\n",
    "    }\n",
    "    \n",
    "    return prompts[query_type].format(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_prompt(query_type: str, query: str) -> str:\n",
    "#     \"\"\"Generate context-aware prompt based on query type\"\"\"\n",
    "#     prompts = {\n",
    "#         'location': \"\"\"You are a location-aware assistant. For questions about rooms or tasks:\n",
    "#                      1. Do not include information based on universal truths or unrelated topics. If the requested information is not available in the document, respond with: \n",
    "#                        \"I cannot find information about this room/task in the available documents.\"\n",
    "#                      2. ONLY use information from 'Rooms_And_Tasks.pdf'\n",
    "#                      3. Ignore all other documents completely for room/task questions\n",
    "#                      4. Provide specific task details for the requested room\n",
    "#                      5. If the information isn't in Rooms_And_Tasks.pdf, say \"I cannot find information about this room/task in the available documents.\"\n",
    "                     \n",
    "#                      Question: {query}\"\"\",\n",
    "                     \n",
    "#         'cybersecurity': \"\"\"You are a cybersecurity expert. For security questions:\n",
    "#                            1. Avoid using general or universal knowledge that is not explicitly available in the resources. If the information is not in the documents, respond with: \n",
    "#                              \"I cannot find information about this topic in the available documents.\"\n",
    "#                            2. Prioritize information from cybersecurity guides and best practices\n",
    "#                            3. Provide specific, actionable security information\n",
    "#                            4. Only include room or system information if directly relevant to security\n",
    "                           \n",
    "#                            Question: {query}\"\"\",\n",
    "        \n",
    "#         'system': \"\"\"You are a system configuration assistant. For system questions:\n",
    "#                     1. Do not include information based on universal truths or unrelated topics. If the requested information is not in the documents, respond with: \n",
    "#                       \"I cannot find information about this system setup in the available documents.\"\n",
    "#                     2. Focus on technical configuration and asset details\n",
    "#                     3. Reference room information only if relevant to system setup\n",
    "#                     4. Include security considerations only if directly applicable\n",
    "                    \n",
    "#                     Question: {query}\"\"\",\n",
    "        \n",
    "#         'other': \"\"\"You are a helpful assistant. Answer the following question ONLY if the information is found in the provided documents. If the requested information is not available in the resources, respond with: \n",
    "#                      \"I cannot answer this question based on the available documents.\"\n",
    "#                     Question: {query}\"\"\"\n",
    "#     }\n",
    "    \n",
    "#     return prompts[query_type].format(query=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query processing\n",
    "We want our system to be able to answer questions both context and content based.\n",
    "- Rule based classification\n",
    "- Generate final prompt based on the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(query: str):\n",
    "    \"\"\"\n",
    "    Processes a user query, generates an answer using loaded files, \n",
    "    and returns the answer along with execution times for various parts of the process.\n",
    "\n",
    "    Parameters:\n",
    "    - query (str): The user's question or query that needs to be answered.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing the generated answer (str) and a dictionary of execution times (dict).\n",
    "\n",
    "    Workflow:\n",
    "    1. Checks if any files are loaded; raises an exception if none are available.\n",
    "    2. Records the time taken for initial checks.\n",
    "    3. Checks the cache for previously answered queries to optimize response time.\n",
    "    4. Detects the type of query (location, cybersecurity, system, etc.) to prioritize relevant documents.\n",
    "    5. Prepares a prompt for the generative model, including the user's question.\n",
    "    6. Selects and prioritizes relevant files based on the query type, adjusting the history context accordingly.\n",
    "    7. Sends the prepared prompt to the chat session and measures the response time.\n",
    "    8. Caches the generated response for future reference.\n",
    "    9. Returns the generated answer and timing metrics.\n",
    "    \n",
    "    Exception Handling:\n",
    "    - If an error occurs during processing, it logs the error message along with the time taken until the error occurred.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize timing dictionary and start overall timing\n",
    "    timings = {}\n",
    "    start_time = time.time()\n",
    "    global history\n",
    "\n",
    "    try:\n",
    "        # Ensure files are loaded for processing\n",
    "        if not files:\n",
    "            raise Exception(\"No files loaded. Please load files first using load_files()\")\n",
    "        \n",
    "        # Record time taken for initial file check\n",
    "        timings['initial_check'] = time.time() - start_time\n",
    "        \n",
    "        # Check cache first to save time on repeated queries\n",
    "        if query in cached_responses:\n",
    "            return cached_responses[query], {'cached': True, 'total_time': time.time() - start_time}\n",
    "\n",
    "        # Prepare the chat context and prompt for the query\n",
    "        query_type = detect_query_type(query)\n",
    "        print(f\"Detected query type: {query_type}\")\n",
    "        # prompt_intro = \"You are a question answering model. Please answer the following question briefly and to the point. If there are multiple points found, give them all as it is and list them in a list. The question is:\"\n",
    "        # prompt = prompt_intro + \" \" + query\n",
    "        prompt = generate_prompt(query_type, query)\n",
    "        \n",
    "        # Prioritize relevant files for location queries\n",
    "        relevant_files_start_time = time.time()\n",
    "        relevant_files = files\n",
    "\n",
    "        # Separate and prioritize files based on query type\n",
    "        if query_type == 'location':\n",
    "            prioritized_files = [file for file in files if 'Rooms_And_Tasks.pdf' in file.display_name]\n",
    "            other_files = [file for file in files if 'Rooms_And_Tasks.pdf' not in file.display_name]\n",
    "            relevant_files = prioritized_files + other_files\n",
    "            \n",
    "        # Record time taken for relevant files selection\n",
    "        timings['relevant_files_selection'] = time.time() - relevant_files_start_time\n",
    "        \n",
    "        # Optimize the history update to keep full content only in prioritized files\n",
    "        history = []\n",
    "        for file in relevant_files:\n",
    "            if query_type == 'location' and 'Rooms_And_Tasks.pdf' in file.display_name:\n",
    "                history.append({\n",
    "                    \"role\": \"user\",\n",
    "                    \"parts\": [file]  # Full content for prioritized files\n",
    "                })\n",
    "            else:\n",
    "                # Use minimal info for other files\n",
    "                history.append({\n",
    "                    \"role\": \"user\",\n",
    "                    \"parts\": [f\"Basic content from {file.display_name}\"]\n",
    "                })\n",
    "        \n",
    "        # Add prompt to history\n",
    "        history.append({\n",
    "            \"role\": \"user\",\n",
    "            \"parts\": [prompt]\n",
    "        })\n",
    "        \n",
    "        # Apply history if this is a location query or complex question\n",
    "        if query_type == 'location':\n",
    "            chat_session.history = history\n",
    "        \n",
    "        # Get response from chat session\n",
    "        response_start_time = time.time()\n",
    "        response = chat_session.send_message(prompt, safety_settings=safety_settings)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        timings['response_time'] = end_time - response_start_time  # Time for getting response\n",
    "        timings['total_time'] = end_time - start_time  # Total time taken\n",
    "        \n",
    "        # Cache the response for future queries\n",
    "        cached_responses[query] = response.text\n",
    "        \n",
    "        return response.text, timings  # Return the generated answer and timing breakdown\n",
    "        \n",
    "    except Exception as e:\n",
    "        end_time = time.time()\n",
    "        print(f\"\\nError occurred after {end_time - start_time:.2f} seconds\")\n",
    "        print(f\"Error processing query: {str(e)}\")\n",
    "        return f\"An error occurred: {str(e)}\", timings  # Return the error message and timings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache and History (inference time optimization)\n",
    "- Cache:  re-fetch data for identical queries, leading to faster response times\n",
    "- History:\n",
    "    1. Contextual Awareness: Maintains conversation context for better responses.\n",
    "    2. Prioritization of Relevant Information: Provides full content for key files based on query_type.\n",
    "    3. Efficiency: Uses minimal info for less critical files, speeding up responses.\n",
    "    4. Improved Response Quality: Generates nuanced responses based on diverse user inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PA Question and Answering System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gemini_qa_system(query, load_resource=True):\n",
    "    \"\"\"\n",
    "    Manages the Gemini Question and Answering system, handling resource loading, \n",
    "    evaluation, and query processing based on the provided parameters.\n",
    "\n",
    "    Parameters:\n",
    "    - query (str): The user query for which an answer is requested. Defaults to an empty string.\n",
    "    - load_resource (bool): Indicates whether to load resources before processing. Defaults to True.\n",
    "\n",
    "    Workflow:\n",
    "    1. Initializes an instance of the GeminiQuestion_and_Answering class.\n",
    "    2. Loads resources if the load_resource parameter is set to True.\n",
    "    3. If a query is provided, retrieves and prints the generated answer from the system.\n",
    "\n",
    "    Returns:\n",
    "    - None: The function prints the generated answer to the console if a query is provided.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load resources if specified\n",
    "    if load_resource:\n",
    "        load_resources(load_resource=True)\n",
    "        \n",
    "    answer = get_answer(query)\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test PA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file '10 cybersecurity best practices.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/rd8glolm9dnm\n",
      "Uploaded file 'Directory Design Idea.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/o93as0wglllq\n",
      "Uploaded file 'Direction for how to use controllers in uSucceed.docx.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/n0000bef63or\n",
      "Uploaded file 'DDoS-Attacks.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/bh7fbune8n6f\n",
      "Uploaded file '6 types of cybersecurity attacks.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/1ynu8rrgnb9g\n",
      "Uploaded file 'CONTEXT_Rooms_And_Tasks.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/9mo8qpp3ua5k\n",
      "Uploaded file '2024 Cybersecurity Guide by norton.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/aslb40vwk836\n",
      "Uploaded file 'Learning-based_Image_Analytics_in_User-AI_Agent_Interactions_for_Cyber-enabled_Manufacturing.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/xifg6a9xvrxx\n",
      "Waiting for file processing...\n",
      "...all files ready\n",
      "\n",
      "Detected query type: location\n"
     ]
    }
   ],
   "source": [
    "query=\"I am at 'Room 1'. what is my task here?\"\n",
    "answer = gemini_qa_system(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "In Room 1, your tasks are:\n",
      "\n",
      "* **Task 1:** Watch a video.\n",
      "* **Task 2:** Run a System Health check.\n",
      "\n",
      "\n",
      "Response Time: 1.7285449504852295 seconds\n"
     ]
    }
   ],
   "source": [
    "answer_text = answer[0]\n",
    "response_time = answer[1]['total_time']\n",
    "\n",
    "print(f\"Answer:\\n{answer_text}\\n\")\n",
    "print(f\"Response Time: {response_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file '10 cybersecurity best practices.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/r57lw4w7dsa9\n",
      "Uploaded file 'Directory Design Idea.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/ck9buyhrmxxk\n",
      "Uploaded file 'Direction for how to use controllers in uSucceed.docx.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/3jt9a9o9jk4k\n",
      "Uploaded file 'DDoS-Attacks.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/h4aty2rebikv\n",
      "Uploaded file '6 types of cybersecurity attacks.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/rcvpuf0qbhs0\n",
      "Uploaded file 'CONTEXT_Rooms_And_Tasks.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/nxrvqi1rkxiy\n",
      "Uploaded file '2024 Cybersecurity Guide by norton.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/nnua22ufal31\n",
      "Uploaded file 'Learning-based_Image_Analytics_in_User-AI_Agent_Interactions_for_Cyber-enabled_Manufacturing.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/h32g5gn89nkl\n",
      "Waiting for file processing...\n",
      "...all files ready\n",
      "\n",
      "Detected query type: other\n",
      "Answer:\n",
      "I cannot answer this question based on the available documents.\n",
      "\n",
      "\n",
      "Response Time: 0.4420051574707031 seconds\n"
     ]
    }
   ],
   "source": [
    "query=\"what is 5 + 5?\"\n",
    "answer = gemini_qa_system(query)\n",
    "answer_text = answer[0]\n",
    "response_time = answer[1]['total_time']\n",
    "\n",
    "print(f\"Answer:\\n{answer_text}\\n\")\n",
    "print(f\"Response Time: {response_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file '10 cybersecurity best practices.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/p276f2evanov\n",
      "Uploaded file 'Directory Design Idea.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/4d9mogt6a3st\n",
      "Uploaded file 'Direction for how to use controllers in uSucceed.docx.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/m2t8yt8xk2y\n",
      "Uploaded file 'DDoS-Attacks.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/c8ged0366ui0\n",
      "Uploaded file '6 types of cybersecurity attacks.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/kztyqseg6hgk\n",
      "Uploaded file 'CONTEXT_Rooms_And_Tasks.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/dm7ccpkgfdzl\n",
      "Uploaded file '2024 Cybersecurity Guide by norton.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/qkyfzfufm1m1\n",
      "Uploaded file 'Learning-based_Image_Analytics_in_User-AI_Agent_Interactions_for_Cyber-enabled_Manufacturing.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/yo5k7nholr5x\n",
      "Waiting for file processing...\n",
      "...all files ready\n",
      "\n",
      "Detected query type: other\n",
      "Answer:\n",
      "I cannot answer this question based on the available documents.\n",
      "\n",
      "\n",
      "Response Time: 0.4621710777282715 seconds\n"
     ]
    }
   ],
   "source": [
    "query=\"who killed harambe?\"\n",
    "answer = gemini_qa_system(query)\n",
    "answer_text = answer[0]\n",
    "response_time = answer[1]['total_time']\n",
    "\n",
    "print(f\"Answer:\\n{answer_text}\\n\")\n",
    "print(f\"Response Time: {response_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file '10 cybersecurity best practices.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/5wacpocsa94c\n",
      "Uploaded file 'Directory Design Idea.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/ya8trfd0537i\n",
      "Uploaded file 'Direction for how to use controllers in uSucceed.docx.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/5xhvfsizu8qa\n",
      "Uploaded file 'DDoS-Attacks.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/dkeljlmfj766\n",
      "Uploaded file '6 types of cybersecurity attacks.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/4clg5mp7k1lc\n",
      "Uploaded file 'CONTEXT_Rooms_And_Tasks.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/6feisderd76u\n",
      "Uploaded file '2024 Cybersecurity Guide by norton.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/3aysbep3tcfh\n",
      "Uploaded file 'Learning-based_Image_Analytics_in_User-AI_Agent_Interactions_for_Cyber-enabled_Manufacturing.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/mn822hd97qox\n",
      "Waiting for file processing...\n",
      "...all files ready\n",
      "\n",
      "Detected query type: cybersecurity\n",
      "Answer:\n",
      "A Distributed Denial-of-Service (DDoS) attack is a cyberattack where multiple compromised systems (often called bots or zombies) flood the target system with traffic, overwhelming its resources and making it unavailable to legitimate users.  Unlike a single-source Denial-of-Service (DoS) attack, a DDoS attack originates from numerous sources, making it significantly harder to mitigate.\n",
      "\n",
      "**How it works:**  Attackers typically compromise numerous devices (IoT devices, servers, etc.) through malware or phishing campaigns.  These compromised devices are then coordinated to send a massive volume of requests to the target, exhausting its bandwidth, processing power, or other resources.  This can manifest in various ways, including:\n",
      "\n",
      "* **Volume-based attacks:**  Overwhelming the target with sheer volume of traffic.  Examples include UDP floods and ICMP floods.\n",
      "* **Protocol attacks:** Exploiting vulnerabilities in network protocols to disrupt service.  Examples include SYN floods and HTTP floods.\n",
      "* **Application-layer attacks:** Targeting specific applications or services on the target system.  Examples include HTTP GET floods and Slowloris attacks.\n",
      "\n",
      "\n",
      "**Security Implications:** DDoS attacks can cause significant disruption, including:\n",
      "\n",
      "* **Website downtime:**  Preventing users from accessing websites or online services.\n",
      "* **Service outages:**  Disrupting critical services, such as online banking or e-commerce.\n",
      "* **Financial losses:**  Resulting from lost revenue, reputational damage, and legal liabilities.\n",
      "* **Data breaches:**  While not a direct consequence, a successful DDoS attack can distract from other malicious activities, potentially leading to a secondary breach.\n",
      "\n",
      "\n",
      "**Mitigation Strategies:**  Effective DDoS mitigation requires a multi-layered approach, including:\n",
      "\n",
      "* **Network-level mitigation:** Implementing firewalls, intrusion detection/prevention systems (IDS/IPS), and content delivery networks (CDNs) with DDoS protection capabilities.\n",
      "* **Application-level mitigation:** Using web application firewalls (WAFs) to filter malicious traffic targeting specific applications.\n",
      "* **Rate limiting:**  Restricting the number of requests from a single IP address or network.\n",
      "* **Cloud-based DDoS protection:** Leveraging cloud providers' DDoS mitigation services.\n",
      "* **Proactive security measures:** Regularly patching systems, implementing strong passwords, and educating users about phishing and malware.\n",
      "\n",
      "\n",
      "It's crucial to have a comprehensive DDoS mitigation plan in place *before* an attack occurs.  This plan should include identifying critical systems, establishing monitoring capabilities, and defining incident response procedures.  Regular security audits and penetration testing can help identify vulnerabilities that could be exploited in a DDoS attack.\n",
      "\n",
      "\n",
      "Response Time: 4.215511083602905 seconds\n"
     ]
    }
   ],
   "source": [
    "query=\"what is DDos?\"\n",
    "answer = gemini_qa_system(query)\n",
    "answer_text = answer[0]\n",
    "response_time = answer[1]['total_time']\n",
    "\n",
    "print(f\"Answer:\\n{answer_text}\\n\")\n",
    "print(f\"Response Time: {response_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before you begin your journey in uSucceed, let’s walk through a quick tutorial on how to use \n",
      "your VR controllers and interact with your personalized assistant, Robi.  \n",
      "Controller Overview:  \n",
      "- Joysticks for Navigation:  \n",
      "o The left joystick  controls your movement. Push it forward or backward to \n",
      "move in those directions, and push it left or right to strafe.  \n",
      "o The right joystick  rotates your digital avatar. Use it to turn and change \n",
      "your perspective.  \n",
      "- Trigger Buttons for Interaction:  \n",
      "o To select or interact with objects, point your controller at the item and \n",
      "press the trigger button . \n",
      "Adjusting Movement Speed:  \n",
      "- Use the left joystick  to control your movement speed:  \n",
      "o Push the joystick halfway forward  for a slower pace.  \n",
      "o Push it all the way forward  for normal speed.  \n",
      "o For faster movement, press the joystick button  down while pushing it all \n",
      "the way forward.  \n",
      "Interacting with Robi:  \n",
      "o To summon Robi, press the B button  on your right controller. Look \n",
      "around until you see Robi appear in the scene.  \n",
      "o Once you spot Robi, press the A button  on the same controller to start \n",
      "the conversation.  \n",
      "o Wait for Robi to ask, \"How can I help you?\" before speaking. Robi won’t \n",
      "hear you if you start talking too soon or while Robi is speaking. Make sure \n",
      "to let Robi finish responding to your questions or requests without \n",
      "interruption.  \n",
      "Feel free to ask Robi simple questions, like \"What is cybersecurity?\"  \n",
      "Handling Objects:  \n",
      "o Use the Grip buttons  on either side of your controllers to pick up, hold, \n",
      "and drop cybersecurity icons into the correct box.  \n",
      " \n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Before you begin your journey in uSucceed, let’s walk through a quick tutorial on how to use \\nyour VR controllers and interact with your personalized assistant, Robi.  \\nController Overview:  \\n- Joysticks for Navigation:  \\no The left joystick  controls your movement. Push it forward or backward to \\nmove in those directions, and push it left or right to strafe.  \\no The right joystick  rotates your digital avatar. Use it to turn and change \\nyour perspective.  \\n- Trigger Buttons for Interaction:  \\no To select or interact with objects, point your controller at the item and \\npress the trigger button . \\nAdjusting Movement Speed:  \\n- Use the left joystick  to control your movement speed:  \\no Push the joystick halfway forward  for a slower pace.  \\no Push it all the way forward  for normal speed.  \\no For faster movement, press the joystick button  down while pushing it all \\nthe way forward.  \\nInteracting with Robi:  \\no To summon Robi, press the B button  on your right controller. Look \\naround until you see Robi appear in the scene.  \\no Once you spot Robi, press the A button  on the same controller to start \\nthe conversation.  \\no Wait for Robi to ask, \"How can I help you?\" before speaking. Robi won’t \\nhear you if you start talking too soon or while Robi is speaking. Make sure \\nto let Robi finish responding to your questions or requests without \\ninterruption.  \\nFeel free to ask Robi simple questions, like \"What is cybersecurity?\"  \\nHandling Objects:  \\no Use the Grip buttons  on either side of your controllers to pick up, hold, \\nand drop cybersecurity icons into the correct box.  \\n \\n '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PyPDF2\n",
    "nav_path = \"../uSucceed_resource/NAVIGATION_control.pdf\"\n",
    "def read_pdf():\n",
    "    with open(nav_path, \"rb\") as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = []\n",
    "        for page in reader.pages:\n",
    "            text.append(page.extract_text())\n",
    "        nav_guide = \"\\n\".join(text)\n",
    "    return nav_guide\n",
    "read_pdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BeforeyoubeginyourjourneyinuSucceed,let’swalkthroughaquicktutorialonhowtouse\\nyourVRcontrollersandinteractwithyourpersonalizedassistant,Robi.\\nControllerOverview:\\n1. JoysticksforNavigation:\\no Theleftjoystickcontrolsyourmovement.Pushitforwardorbackwardtomove\\ninthosedirections,andpushitleftorrighttostrafe.\\no Therightjoystickrotatesyourdigitalavatar.Useittoturnandchangeyour\\nperspective.\\n2. TriggerButtonsforInteraction:\\no Toselectorinteractwithobjects,pointyourcontrollerattheitemandpressthe\\ntriggerbutton.\\nAdjustingMovementSpeed:\\n● Usetheleftjoysticktocontrolyourmovementspeed:\\no Pushthejoystickhalfwayforwardforaslowerpace.\\no Pushitallthewayforwardfornormalspeed.\\no Forfastermovement,pressthejoystickbuttondownwhilepushingitalltheway\\nforward.\\nInteractingwithRobi:\\n● TosummonRobi,presstheBbuttononyourrightcontroller.Lookarounduntilyousee\\nRobiappearinthescene.\\n● OnceyouspotRobi,presstheAbuttononthesamecontrollertostarttheconversation.\\n● WaitforRobitoask,\"HowcanIhelpyou?\"beforespeaking.Robiwon’thearyouifyou\\nstarttalkingtoosoonorwhileRobiisspeaking.MakesuretoletRobifinishresponding\\ntoyourquestionsorrequestswithoutinterruption.\\nFeelfreetoaskRobisimplequestions,like\"Whatiscybersecurity?\"\\nHandlingObjects:\\n● UsetheGripbuttonsoneithersideofyourcontrollerstopickup,hold,anddrop\\ncybersecurityiconsintothecorrectbox.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pdfplumber\n",
    "def read_pdf():\n",
    "    text = []\n",
    "    with pdfplumber.open(nav_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            page_text = page.extract_text(x_tolerance=3, y_tolerance=3)\n",
    "            if page_text:\n",
    "                text.append(page_text)\n",
    "    nav_guide = \"\\n\".join(text)\n",
    "    return nav_guide\n",
    "read_pdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
